"""
this file is for the manage of the agents
Author: Zachary
Reserved Rights
"""

from mcts_agent import MCTS_Agent
from env_gobang.gomoku import Gomoku
from mcts_tree import Node
import numpy as np

load_model = False
max_mcts_episode = 3000 # the episode's number for agent to run the complete mcts
max_mcts_simulation = 20 # the steps that the simulation runs
env = Gomoku(board_size=5, num4win=3)
agent = MCTS_Agent(env, max_mcts_episode=max_mcts_episode) # init the agent
action = [3, 4, 8]
_trajectory = []

if load_model == True:
    mcts_tree = None
    depth = None
    agent.mcts_tree = mcts_tree # set the model's value    

else:
    depth = 0
    node_now = Node(state=env.board_state, depth=0) # root
    mcts_tree = [[node_now]]
    agent.mcts_tree = mcts_tree # set the model's value    

for i in action:
    #print('*' * 40)
    data_return = env.step(i)
    if i == 3 or i == 8:
        node_now = Node(father=node_now, state=data_return['state'].copy())
        _trajectory.append([depth, 0])
        depth += 1 # update the record
    mcts_tree.append([node_now])
    #print("win {} player {}".format(data_return['terminal'], data_return['reward']))
    #env.visualize() 
#print('the tree is', mcts_tree)
#env.visualize() 
#print('the 1-0 state is ', mcts_tree[1][0].state)
print('game start', '^'*30)
print(agent.act())
#print(mcts_tree)
